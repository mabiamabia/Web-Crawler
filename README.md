# Web-Crawler
Essa aplicação navega por um site em busca de termos fornecidos pelo usuário

Web Crawlers são rastreadores da web, eles devem obter o conteudo da página de um URL, analisar essa pagina e repetir esse processo.
Esse sistema pode ser utilizado, por exemplo, para: Gerar um mapa do site e contar quantos designs de paginas seriam necessários e o volume de conteudo que seria migrado ou também para coleta de dados.

Estrutura:

API Http
Metodo get
Metodo Post

ArrayList
Para evitar que a mesma página fosse rastreada mais de uma vez


Tecnologias utilizadas:

Java, Apache Maven, Docker, Eclipse IDE

Bibliotecas utilizadas:

Jsoup, Spark, Gson, SLF4J, JUnit5, Hamcrest, Apache commons Lang e Mockito

![crawler](https://user-images.githubusercontent.com/49458473/131124764-4482b7f2-5c01-442c-91c4-fb78a1cc53a4.png)










